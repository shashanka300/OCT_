{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-dev20190318\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)\n",
    "from tensorflow.keras.layers import Input,add,Conv2D\n",
    "from tensorflow.python.ops import control_flow_util\n",
    "control_flow_util.ENABLE_CONTROL_FLOW_V2 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def inblock(inp):\n",
    "\n",
    "    print(inp)\n",
    "    shortcut = Conv2D(51,(1,1),activation='relu', padding='same')(inp)\n",
    "\n",
    "    conv3x3 = Conv2D(8, (3, 3),activation='relu', padding='same')(inp)# 32filters of size 3x3\n",
    "\n",
    "    conv5x5 = Conv2D(17,(3, 3),activation='relu', padding='same')(conv3x3)# 32filters of size 3x3\n",
    "\n",
    "    conv7x7 = Conv2D(26, (3, 3),activation='relu', padding='same')(conv5x5)#32filters of size 3x3\n",
    "\n",
    "    out = tf.keras.layers.concatenate([conv3x3, conv5x5, conv7x7], axis=3)\n",
    "    \n",
    "    out = tf.keras.layers.BatchNormalization(axis=3)(out)\n",
    "\n",
    "    #out = tf.keras.layers.add([shortcut, out])\n",
    "    out = tf.keras.layers.concatenate([shortcut, out], axis=3)\n",
    "    \n",
    "    out = tf.keras.layers.Activation('relu')(out)\n",
    "    \n",
    "    out = tf.keras.layers.BatchNormalization(axis=3)(out)\n",
    "    print(\"inblock\",out.shape)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def resblock_A(inp,filter_size):\n",
    "\n",
    "\n",
    "     \n",
    "       # inp = tf.keras.layers.Activation('relu')(inp)    \n",
    "    \n",
    "        B1 = Conv2D(filter_size, (1, 1),activation='relu', padding='same')(inp)# 32filters of size 1x1\n",
    "    \n",
    "        B2 = Conv2D(filter_size, (1, 1),activation='relu', padding='same')(inp)# 32filters of size 1x1\n",
    "    \n",
    "        B2 = Conv2D(filter_size, (3, 3),activation='relu', padding='same')(B2)# 32filters of size 1x1\n",
    "    \n",
    "        B3 = Conv2D(filter_size, (1, 1),activation='relu', padding='same')(inp)# 32filters of size 1x1\n",
    "    \n",
    "        B3 = Conv2D(48, (3, 3),activation='relu', padding='same')(B3)# 32filters of size 1x1\n",
    "    \n",
    "        B3 = Conv2D(64, (3, 3),activation='relu', padding='same')(B3)# 32filters of size 1x1\n",
    "    \n",
    "        out = tf.keras.layers.concatenate([B1, B2, B3], axis=3)\n",
    "    \n",
    "        out = tf.keras.layers.BatchNormalization(axis=3)(out)\n",
    "                       \n",
    "        out = Conv2D(384, (1, 1),activation='relu', padding='same')(out)# 32filters of size 1x1  \n",
    "    \n",
    "        #out = add([inp, out])\n",
    "        out = tf.keras.layers.concatenate([inp, out], axis=3)\n",
    "        out = tf.keras.layers.Activation('relu')(out)\n",
    "        out = tf.keras.layers.BatchNormalization(axis=3)(out)\n",
    "        print(\"resblock_a\",out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def Path_1(inp):\n",
    "\n",
    "\n",
    "    shortcut = Conv2D(32, (1, 1),activation='relu', padding='same')(inp)\n",
    "\n",
    "    out = Conv2D(32, (3, 3), activation='relu', padding='same')(inp)\n",
    "    out = Conv2D( 32, (3, 3), activation='relu', padding='same')(out)\n",
    "\n",
    "    out = add([shortcut, out])\n",
    "    out = tf.keras.layers.Activation('relu')(out)\n",
    "    branch = tf.keras.layers.BatchNormalization(axis=3)(out)\n",
    "    \n",
    "    out = Conv2D( 32, (3, 3), activation='relu', padding='same')(branch)\n",
    "    out = Conv2D( 32, (3, 3), activation='relu', padding='same')(out)\n",
    "\n",
    "    out = add([branch, out])\n",
    "    out = tf.keras.layers.Activation('relu')(out)\n",
    "    out = tf.keras.layers.BatchNormalization(axis=3)(out)\n",
    "\n",
    "    print(\"path\",out.shape)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def reduction_A(inp):\n",
    "\n",
    "    pooling = tf.keras.layers.MaxPooling2D((3,3),2)(inp)\n",
    "    \n",
    "    B1 = Conv2D(inp,384, 3, 3, strides=(2,2))\n",
    "    \n",
    "    B2 = Conv2D(inp,192, 1, 1)# 64filters of size 1x1  \n",
    "    \n",
    "    B2 = Conv2D(B2,224, 3, 3)# 64filters of size 1x1 \n",
    "    \n",
    "    B2 = Conv2D(B2,256, 3, 3,strides=(2,2))# 64filters of size 1x1 \n",
    "    \n",
    "    out = tf.keras.layers.concatenate([B1, B2, pooling], axis=3)\n",
    "    \n",
    "    out = tf.keras.layers.BatchNormalization(axis=3)(out)\n",
    "    #print(out.shape)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def resblock_B(inp):\n",
    "\n",
    "    \n",
    "    B1 = Conv2D(192, (1, 1), activation='relu', padding='same')(inp)# 32filters of size 1x1\n",
    "    \n",
    "    B2 = Conv2D(128, (1, 1), activation='relu', padding='same')(inp)# 32filters of size 1x1\n",
    "    \n",
    "    B2 = Conv2D(160, (1 , 7), activation='relu', padding='same')(B2)\n",
    "    \n",
    "    B2 = Conv2D(192, (7, 1), activation='relu', padding='same')(B2)\n",
    "    \n",
    "    out = tf.keras.layers.concatenate([B1, B2], axis=3)\n",
    "    out = tf.keras.layers.BatchNormalization(axis=3)(out)\n",
    "    out = Conv2D(1154, (1, 1), activation='relu', padding='same')(out)\n",
    "    \n",
    "    #out = add([inp, out])\n",
    "    out = tf.keras.layers.concatenate([inp, out], axis=3)\n",
    "    out = tf.keras.layers.Activation('relu')(out)\n",
    "    out = tf.keras.layers.BatchNormalization(axis=3)(out)\n",
    "    print(\"resblock_B\",out.shape)\n",
    "    return out\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def resblock_C(inp):\n",
    "\n",
    "    \n",
    "    B1 = Conv2D(192, (1, 1), activation='relu', padding='same')(inp)# 32filters of size 1x1\n",
    "    \n",
    "    B2 = Conv2D(192, (1, 1), activation='relu', padding='same')(inp)# 32filters of size 1x1\n",
    "    \n",
    "    B2 = Conv2D(224, (1, 3), activation='relu', padding='same')(B2)\n",
    "    \n",
    "    B2 = Conv2D(256, (3, 1), activation='relu', padding='same')(B2)\n",
    "    \n",
    "    out = tf.keras.layers.concatenate([B1, B2], axis=3)\n",
    "    out = tf.keras.layers.BatchNormalization(axis=3)(out)\n",
    "    out = Conv2D(2048, (1, 1), activation='relu', padding='same')(out)\n",
    "    \n",
    "    #out = add([inp, out])\n",
    "    out = tf.keras.layers.concatenate([inp, out], axis=3)\n",
    "    out = tf.keras.layers.Activation('relu')(out)\n",
    "    out = tf.keras.layers.BatchNormalization(axis=3)(out)\n",
    "    print(\"resblock_c\",out.shape)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def reduction_B(inp):\n",
    "\n",
    "    pooling = tf.keras.layers.MaxPooling2D((3,3),(2,2))(inp)\n",
    "    \n",
    "    B1 = Conv2D(inp, 256, 1, 1)\n",
    "    B1 = Conv2D(B1, 384, 3, 3, strides=(2,2))\n",
    "    \n",
    "    B2 = Conv2D(inp,256, 1, 1)# 64filters of size 1x1\n",
    "    B2 = Conv2D(B2, 288, 1, 1, strides=(2,2))\n",
    "    \n",
    "    B3 = Conv2D(inp, 256, 1, 1)# 64filters of size 1x1 \n",
    "    B3 = Conv2D(B3, 288, 1, 1)\n",
    "    B3 = Conv2D(B3, 320, 1, 1, strides=(2,2))\n",
    "    \n",
    "    out = tf.keras.layers.concatenate([pooling, B1, B2, B3], axis=3)\n",
    "    out = tf.keras.layers.BatchNormalization(axis=3)(out)\n",
    "    print(out.shape)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def Path_2(inp):\n",
    "\n",
    "    shortcut = Conv2D(32, (1, 1), activation='relu', padding='same')(inp)\n",
    "\n",
    "    out = Conv2D(32, (3, 3), activation='relu', padding='same')(inp)\n",
    "    out = Conv2D(32, (3, 3), activation='relu', padding='same')(out)\n",
    "\n",
    "    #out = tf.keras.layers.add([shortcut, out])\n",
    "    out = tf.keras.layers.concatenate([shortcut, out], axis=3)\n",
    "    out = tf.keras.layers.Activation('relu')(out)\n",
    "    out = tf.keras.layers.BatchNormalization(axis=3)(out)\n",
    "    \n",
    "    out = Conv2D(32, (3, 3), activation='relu', padding='same')(out)\n",
    "\n",
    "    out = tf.keras.layers.Activation('relu')(out)\n",
    "    out = tf.keras.layers.BatchNormalization(axis=3)(out)\n",
    "    print(\"path2\",out.shape)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def Path_3(inp):\n",
    "\n",
    "\n",
    "    shortcut = Conv2D(32, (1, 1), activation='relu', padding='same')(inp)\n",
    "\n",
    "    out = Conv2D(32, (3, 3), activation='relu', padding='same')(inp)\n",
    "    out = Conv2D(32, (3, 3), activation='relu', padding='same')(out)\n",
    "\n",
    "    #out = tf.keras.layers.add([shortcut, out])\n",
    "    out = tf.keras.layers.concatenate([shortcut, out], axis=3)\n",
    "    out = tf.keras.layers.Activation('relu')(out)\n",
    "    out = tf.keras.layers.BatchNormalization(axis=3)(out)\n",
    "\n",
    "    print(\"path3\",out.shape)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def Path_4(inp):\n",
    "  \n",
    "    #out = conv_2d(inp, 32, 3, 3, activation='relu', padding='valid')\n",
    "    out = Conv2D(32,3,activation='relu',padding='same',strides=(1,1))(inp)\n",
    "   \n",
    "\n",
    "    #out = tf.keras.layers.Activation('relu')(out)\n",
    "    \n",
    "    out = tf.keras.layers.BatchNormalization(axis=3)(out)\n",
    "    print(\"path4\",out.shape)\n",
    "\n",
    "    \n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def AD_net(input_dimension=(256,256,3)):\n",
    " \n",
    "    inputs = Input(input_dimension)\n",
    "    inblock_inp= inblock(inputs)\n",
    "    resblock_a1=resblock_A(inblock_inp,32)\n",
    "    path1=Path_1(resblock_a1)\n",
    "    \n",
    "    #reduction_a=reduction_A(resblock_a1)\n",
    "    reduction_a=tf.keras.layers.MaxPooling2D((2,2))(resblock_a1)\n",
    "    resblock_a2=resblock_A(reduction_a,64)\n",
    "    path2=Path_2(resblock_a2)\n",
    "    \n",
    "    reduction_b=tf.keras.layers.MaxPooling2D((2,2))(resblock_a2)\n",
    "    resblock_b1=resblock_B(reduction_b)\n",
    "    path3=Path_3(resblock_b1)\n",
    "    \n",
    "    Mpooling=tf.keras.layers.MaxPooling2D((2,2))(resblock_b1)\n",
    "    resblock_b2=resblock_B(Mpooling)\n",
    "    path4=Path_4(resblock_b2)\n",
    "    \n",
    "    Mpooling2=tf.keras.layers.MaxPooling2D((2,2))(resblock_b2)\n",
    "    resblock_c=resblock_C(Mpooling2)\n",
    "    \n",
    "    Up1=tf.keras.layers.concatenate([tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(resblock_c),path4],axis=3)\n",
    "    resblock_b2=resblock_B(Up1)\n",
    "\n",
    "    Up2=tf.keras.layers.concatenate([tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(resblock_b2),path3],axis=3)\n",
    "    resblock_b3=resblock_B(Up2)\n",
    "\n",
    "    \n",
    "    Up3=tf.keras.layers.concatenate([tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(resblock_b3),path2],axis=3)\n",
    "    resblock_a3=resblock_A(Up3,64)\n",
    "    \n",
    "    \n",
    "    \n",
    "    Up4=tf.keras.layers.concatenate([tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(resblock_a3),path1],axis=3)\n",
    "    resblock_a4=resblock_A(Up4,32)\n",
    "    outblock=inblock(resblock_a4)\n",
    "    \n",
    "    conv_final=Conv2D(1,(1,1),activation='sigmoid',padding='same')(outblock)\n",
    "    print(\"conv final\",conv_final.shape) \n",
    "    \n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[conv_final])\n",
    "    #modle.compile(tf.keras.optimizer.Adam(lr),loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    #model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou])\n",
    "    return model\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def main():\n",
    "    model=AD_net()\n",
    "    print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_4:0\", shape=(None, 256, 256, 3), dtype=float32)\n",
      "inblock (None, 256, 256, 102)\n",
      "resblock_a (None, 256, 256, 486)\n",
      "path (None, 256, 256, 32)\n",
      "resblock_a (None, 128, 128, 870)\n",
      "path2 (None, 128, 128, 32)\n",
      "resblock_B (None, 64, 64, 2024)\n",
      "path3 (None, 64, 64, 64)\n",
      "resblock_B (None, 32, 32, 3178)\n",
      "path4 (None, 32, 32, 32)\n",
      "resblock_c (None, 16, 16, 5226)\n",
      "resblock_B (None, 32, 32, 1442)\n",
      "resblock_B (None, 64, 64, 1474)\n",
      "resblock_a (None, 128, 128, 480)\n",
      "resblock_a (None, 256, 256, 448)\n",
      "Tensor(\"batch_normalization_73/cond/Identity:0\", shape=(None, 256, 256, 448), dtype=float32)\n",
      "inblock (None, 256, 256, 102)\n",
      "conv final (None, 256, 256, 1)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 256, 256, 8)  224         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 256, 256, 17) 1241        conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 256, 256, 26) 4004        conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 256, 256, 51) 0           conv2d_133[0][0]                 \n",
      "                                                                 conv2d_134[0][0]                 \n",
      "                                                                 conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 256, 256, 51) 204         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 256, 256, 51) 204         concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 256, 256, 102 0           conv2d_132[0][0]                 \n",
      "                                                                 batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 256, 256, 102 0           concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 256, 256, 102 408         activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 256, 256, 32) 3296        batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 256, 256, 32) 3296        batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 256, 256, 48) 13872       conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 256, 256, 32) 3296        batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 256, 256, 32) 9248        conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 256, 256, 64) 27712       conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 256, 256, 128 0           conv2d_136[0][0]                 \n",
      "                                                                 conv2d_138[0][0]                 \n",
      "                                                                 conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 256, 256, 128 512         concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 256, 256, 384 49536       batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 256, 256, 486 0           batch_normalization_49[0][0]     \n",
      "                                                                 conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 256, 256, 486 0           concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 256, 256, 486 1944        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 128, 128, 486 0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 128, 128, 64) 31168       max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 128, 128, 64) 31168       max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 128, 128, 48) 27696       conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 128, 128, 64) 31168       max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 128, 128, 64) 36928       conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 128, 128, 64) 27712       conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 128, 128, 192 0           conv2d_148[0][0]                 \n",
      "                                                                 conv2d_150[0][0]                 \n",
      "                                                                 conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 128, 128, 192 768         concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 128, 128, 384 74112       batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)    (None, 128, 128, 870 0           max_pooling2d_7[0][0]            \n",
      "                                                                 conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 128, 128, 870 0           concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 128, 128, 870 3480        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 64, 64, 870)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 64, 64, 128)  111488      max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 64, 64, 160)  143520      conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 64, 64, 192)  167232      max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 64, 64, 192)  215232      conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)    (None, 64, 64, 384)  0           conv2d_159[0][0]                 \n",
      "                                                                 conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 64, 64, 384)  1536        concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 64, 64, 1154) 444290      batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_51 (Concatenate)    (None, 64, 64, 2024) 0           max_pooling2d_8[0][0]            \n",
      "                                                                 conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 64, 64, 2024) 0           concatenate_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 64, 64, 2024) 8096        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 32, 32, 2024) 0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 32, 32, 128)  259200      max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 32, 32, 160)  143520      conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 32, 32, 192)  388800      max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 32, 32, 192)  215232      conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)    (None, 32, 32, 384)  0           conv2d_167[0][0]                 \n",
      "                                                                 conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 32, 32, 384)  1536        concatenate_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 32, 32, 1154) 444290      batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_54 (Concatenate)    (None, 32, 32, 3178) 0           max_pooling2d_9[0][0]            \n",
      "                                                                 conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 32, 32, 3178) 0           concatenate_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 32, 32, 3178) 12712       activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 16, 16, 3178) 0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 16, 16, 192)  610368      max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 16, 16, 224)  129248      conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 16, 16, 192)  610368      max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 16, 16, 256)  172288      conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_55 (Concatenate)    (None, 16, 16, 448)  0           conv2d_173[0][0]                 \n",
      "                                                                 conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 16, 16, 448)  1792        concatenate_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 16, 16, 2048) 919552      batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_56 (Concatenate)    (None, 16, 16, 5226) 0           max_pooling2d_10[0][0]           \n",
      "                                                                 conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 16, 16, 5226) 0           concatenate_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 16, 16, 5226) 20904       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 32, 32, 32)   915296      batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 32, 32, 256)  5351680     batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 32, 32, 32)   128         conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_57 (Concatenate)    (None, 32, 32, 288)  0           conv2d_transpose_4[0][0]         \n",
      "                                                                 batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 32, 32, 128)  36992       concatenate_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 32, 32, 160)  143520      conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 32, 32, 192)  55488       concatenate_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 32, 32, 192)  215232      conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_58 (Concatenate)    (None, 32, 32, 384)  0           conv2d_178[0][0]                 \n",
      "                                                                 conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 32, 32, 384)  1536        concatenate_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 32, 32, 1154) 444290      batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 64, 64, 32)   582944      batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_59 (Concatenate)    (None, 32, 32, 1442) 0           concatenate_57[0][0]             \n",
      "                                                                 conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 64, 64, 32)   64800       batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 64, 64, 32)   9248        conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 32, 32, 1442) 0           concatenate_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)    (None, 64, 64, 64)   0           conv2d_164[0][0]                 \n",
      "                                                                 conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 32, 32, 1442) 5768        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 64, 64, 64)   0           concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 64, 64, 256)  1476864     batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 64, 64, 64)   256         activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_60 (Concatenate)    (None, 64, 64, 320)  0           conv2d_transpose_5[0][0]         \n",
      "                                                                 batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 64, 64, 128)  41088       concatenate_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 64, 64, 160)  143520      conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 64, 64, 192)  61632       concatenate_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 64, 64, 192)  215232      conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 128, 128, 32) 250592      batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_61 (Concatenate)    (None, 64, 64, 384)  0           conv2d_183[0][0]                 \n",
      "                                                                 conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 128, 128, 32) 27872       batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 128, 128, 32) 9248        conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 64, 64, 384)  1536        concatenate_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 128, 128, 64) 0           conv2d_155[0][0]                 \n",
      "                                                                 conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 64, 64, 1154) 444290      batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 128, 128, 64) 0           concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_62 (Concatenate)    (None, 64, 64, 1474) 0           concatenate_60[0][0]             \n",
      "                                                                 conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 128, 128, 64) 256         activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 64, 64, 1474) 0           concatenate_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 128, 128, 32) 18464       batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 64, 64, 1474) 5896        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 128, 128, 32) 0           conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTrans (None, 128, 128, 64) 377408      batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 128, 128, 32) 128         activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_63 (Concatenate)    (None, 128, 128, 96) 0           conv2d_transpose_6[0][0]         \n",
      "                                                                 batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 128, 128, 64) 6208        concatenate_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 256, 256, 32) 140000      batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 128, 128, 64) 6208        concatenate_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 128, 128, 48) 27696       conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 256, 256, 32) 15584       batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 256, 256, 32) 9248        conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 128, 128, 64) 6208        concatenate_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 128, 128, 64) 36928       conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 128, 128, 64) 27712       conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 256, 256, 32) 0           conv2d_143[0][0]                 \n",
      "                                                                 conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_64 (Concatenate)    (None, 128, 128, 192 0           conv2d_188[0][0]                 \n",
      "                                                                 conv2d_190[0][0]                 \n",
      "                                                                 conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 256, 256, 32) 0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 128, 128, 192 768         concatenate_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 256, 256, 32) 128         activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 128, 128, 384 74112       batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 256, 256, 32) 9248        batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_65 (Concatenate)    (None, 128, 128, 480 0           concatenate_63[0][0]             \n",
      "                                                                 conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 256, 256, 32) 9248        conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 128, 128, 480 0           concatenate_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 256, 256, 32) 0           batch_normalization_52[0][0]     \n",
      "                                                                 conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 128, 128, 480 1920        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 256, 256, 32) 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTrans (None, 256, 256, 32) 61472       batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 256, 256, 32) 128         activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_66 (Concatenate)    (None, 256, 256, 64) 0           conv2d_transpose_7[0][0]         \n",
      "                                                                 batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 256, 256, 32) 2080        concatenate_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 256, 256, 32) 2080        concatenate_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 256, 256, 48) 13872       conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 256, 256, 32) 2080        concatenate_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 256, 256, 32) 9248        conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 256, 256, 64) 27712       conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_67 (Concatenate)    (None, 256, 256, 128 0           conv2d_195[0][0]                 \n",
      "                                                                 conv2d_197[0][0]                 \n",
      "                                                                 conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 256, 256, 128 512         concatenate_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 256, 256, 384 49536       batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_68 (Concatenate)    (None, 256, 256, 448 0           concatenate_66[0][0]             \n",
      "                                                                 conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 256, 256, 448 0           concatenate_68[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 256, 256, 448 1792        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 256, 256, 8)  32264       batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 256, 256, 17) 1241        conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 256, 256, 26) 4004        conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_69 (Concatenate)    (None, 256, 256, 51) 0           conv2d_203[0][0]                 \n",
      "                                                                 conv2d_204[0][0]                 \n",
      "                                                                 conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 256, 256, 51) 22899       batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 256, 256, 51) 204         concatenate_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_70 (Concatenate)    (None, 256, 256, 102 0           conv2d_202[0][0]                 \n",
      "                                                                 batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 256, 256, 102 0           concatenate_70[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 256, 256, 102 408         activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 256, 256, 1)  103         batch_normalization_75[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 16,908,456\n",
      "Trainable params: 16,870,828\n",
      "Non-trainable params: 37,628\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
